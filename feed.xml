<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://goq2q.net/feed.xml" rel="self" type="application/atom+xml" /><link href="https://goq2q.net/" rel="alternate" type="text/html" /><updated>2021-11-06T23:56:31-06:00</updated><id>https://goq2q.net/feed.xml</id><title type="html">Q2Q</title><subtitle>Next-gen sound cueing software for live theatre for macOS and Windows</subtitle><author><name>John Wostenberg</name></author><entry><title type="html">I reinvented the wheel last week, and here’s why</title><link href="https://goq2q.net/blog/tech/i-reinvented-the-wheel-last-week-heres-why" rel="alternate" type="text/html" title="I reinvented the wheel last week, and here’s why" /><published>2021-10-26T00:00:00-06:00</published><updated>2021-10-26T00:00:00-06:00</updated><id>https://goq2q.net/blog/tech/i-reinvented-the-wheel-last-week-heres-why</id><content type="html" xml:base="https://goq2q.net/blog/tech/i-reinvented-the-wheel-last-week-heres-why">&lt;p&gt;Common wisdom tells you that many problems worth solving have already been solved for you (probably more than once), and that you should leverage this fact. In other words: don’t reinvent the wheel; stand on the shoulders of giants. I very often follow this rule of thumb. But last week, I broke that rule and wrote &lt;a href=&quot;https://github.com/jwosty/FSharp.Osc&quot;&gt;an F# implementation&lt;/a&gt; of the &lt;a href=&quot;http://opensoundcontrol.org/&quot;&gt;OSC (Open Sound Control) protocol&lt;/a&gt;&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog/2021-10-16-i-reinvented-the-wheel-last-week-heres-why/caveman-square-wheels-m.jpg&quot; alt=&quot;Caveman pushing cart with square wheels&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But first, what is OSC? Here’s a quick and incomplete overview (there’s plenty of information elsewhere on the intertubes): OSC is a simple but very flexible message format, used to allow devices or applications to talk to each other in ad-hoc and arbitrary ways. An OSC message consists of an address string, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;/oscillators/1/frequency&quot;&lt;/code&gt;, and a list of arguments (which can be things like strings, integers, floats, etc). An OSC client sends messages to a server, which will attempt to &lt;em&gt;dispatch&lt;/em&gt; the message based on the functionality it decides to expose. OSC also has pattern matching, which allows, for example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;/oscillators/*/frequency&quot;&lt;/code&gt; to simultaneously dispatch to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;/oscillators/1/frequency&quot;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;oscillators/2/frequency&quot;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;oscillators/foobar/frequency&quot;&lt;/code&gt;, etc. It is quite powerful and flexible, and &lt;a href=&quot;http://opensoundcontrol.org/page-list.html#implementations&quot;&gt;lots of things speak OSC&lt;/a&gt;. The spec defines simple encodings for these messages&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. It was originally intended for use in music- and audio-based applications (such as synthesizers) as a potential alternative to MIDI, but has enjoyed wider multimedia applicability in things like lighting, animatronics, and robotics (to name a few).&lt;/p&gt;

&lt;p&gt;Q2Q support for OSC (both sending a receiving) is the latest feature I’ve been working on, and it’s been a rabbit hole, but boy, has it been a fun rabbit hole. Since Q2Q is written in &lt;a href=&quot;https://fsharp.org/&quot;&gt;F#&lt;/a&gt;, I was looking for ways to send/receive OSC messages in the language. Though F# has &lt;a href=&quot;fsprojects&quot;&gt;a strong open-source community&lt;/a&gt;, it’s not too surprising that nobody has published a first-class OSC library. There are C# OSC libraries (such as &lt;a href=&quot;https://github.com/ValdemarOrn/SharpOSC&quot;&gt;SharpOsc&lt;/a&gt;), but I didn’t consider them an option because I knew I really wanted all the goodies that well-designed F#-oriented code awards you, such as &lt;a href=&quot;https://fsharpforfunandprofit.com/posts/correctness-immutability/#reasons-why-immutability-is-important&quot;&gt;immutability&lt;/a&gt;, &lt;a href=&quot;https://fsharpforfunandprofit.com/posts/designing-with-types-making-illegal-states-unrepresentable/&quot;&gt;making illegal states unrepresentable&lt;/a&gt;, and &lt;a href=&quot;https://fsharpforfunandprofit.com/posts/recipe-part2/&quot;&gt;railway-oriented programming (ROP)&lt;/a&gt;, &lt;a href=&quot;http://learnyouahaskell.com/making-our-own-types-and-typeclasses#algebraic-data-types&quot;&gt;algebraic data types&lt;/a&gt;—the list goes on. So I decided to reinvent the wheel and build an OSC library in F#. Besides, &lt;a href=&quot;https://blog.codinghorror.com/dont-reinvent-the-wheel-unless-you-plan-on-learning-more-about-wheels/&quot;&gt;this was a wheel I wanted to learn about&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The specs for &lt;a href=&quot;http://opensoundcontrol.org/spec-1_0.html&quot;&gt;OSC 1.0&lt;/a&gt; and &lt;a href=&quot;http://opensoundcontrol.org/files/2009-NIME-OSC-1.1.pdf&quot;&gt;OSC 1.1&lt;/a&gt; are pretty short as far as specs go; only a couple pages each—you could read them over lunch. This makes it pretty straightforward to just drive out the whole implementation using &lt;a href=&quot;https://martinfowler.com/bliki/TestDrivenDevelopment.html&quot;&gt;TDD (Test Drive Development)&lt;/a&gt;. The entire OSC 1.1 AST (excluding bundles and timetags, which I just didn’t get around to) consists of the following:&lt;/p&gt;

&lt;div class=&quot;language-fsharp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscAtom&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscInt32&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscFloat32&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscString&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscBlob&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blobData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscBool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscNone&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscImpulse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscMessage&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;addressPattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arguments&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OscAtom&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Boom, &lt;a href=&quot;https://fsharpforfunandprofit.com/ddd/&quot;&gt;Domain Designed&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Next step: Implementing each of the encoding/decoding functions for the atoms and messages, according to the spec. After that: the message dispatching / matching logic (which F# &lt;a href=&quot;https://github.com/jwosty/FSharp.Osc/blob/master/src/FSharp.Osc.fs#L253&quot;&gt;is particularly good at&lt;/a&gt;). Then, finally: the code that fires these messages over the wire (I wrote both UDP and TCP clients), as well as the code that can listen for OSC messages coming in from the network (UDP only for now). The whole thing is just shy of 600 lines of code. Sure, I could have spent that time doing other Q2Q features. But in this case, the advantages outweigh the time spent: this implementation will fit right in with the rest of Q2Q’s idiomatic F# codebase, and I know for a fact that it is correct to the spec&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; since it has &lt;a href=&quot;https://github.com/jwosty/FSharp.Osc/blob/master/Tests/Program.fs&quot;&gt;complete test coverage&lt;/a&gt;. There’s almost 2x the lines of test code than actual code. Sometimes that could be a code smell, but I would argue that it’s not when you’re implementing a protocol from its spec.&lt;/p&gt;

&lt;p&gt;Do I always recommend reinventing the wheel? Definitely not. Would I recommend trying it from time to time? Absolutely.&lt;/p&gt;

&lt;p&gt;Coming soon to theaters near you: OSC support in Q2Q 0.5.0! In the mean time, for geeks like me, you can &lt;a href=&quot;https://github.com/jwosty/FSharp.Osc&quot;&gt;browse the source code&lt;/a&gt;, or &lt;a href=&quot;https://www.nuget.org/packages/FSharp.Osc/&quot;&gt;use the NuGet package&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;em&gt;Um, ackshually, it’s a content format, not a protocol…&lt;/em&gt; Yes, I know, dear reader, and they spell this out in &lt;a href=&quot;http://opensoundcontrol.org/files/2009-NIME-OSC-1.1.pdf&quot;&gt;the OSC 1.1 spec&lt;/a&gt;. I called it that for sake of simplicity. Calling it a “content format” may be more correct, but I think “protocol” gives a better connotation in that opening paragraph. You may notice that I more correctly use the “content format” description later on. Whatever, go ahead and crucify me for that if you’re feeling particularly pedantic today. I’ll still love you. You—yes, you, beloved reader. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;There’s also bundles, which I don’t get into this post. You can read more about those elsewhere. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Well, as long as the messages coming in are well-formed. It doesn’t have particularly good handling of error cases for now, but I can always circle back later. The client also doesn’t do a particularly good job of sanitizing the messages before they’re sent (i.e. preventing you from using an address without a slash at the beginning). &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>John Wostenberg</name></author><category term="tech" /><summary type="html">Common wisdom tells you that many problems worth solving have already been solved for you (probably more than once), and that you should leverage this fact. In other words: don’t reinvent the wheel; stand on the shoulders of giants. I very often follow this rule of thumb. But last week, I broke that rule and wrote an F# implementation of the OSC (Open Sound Control) protocol1. Um, ackshually, it’s a content format, not a protocol… Yes, I know, dear reader, and they spell this out in [the OSC 1.1 spec][osc-1.1]. I called it that for sake of simplicity. Calling it a “content format” may be more correct, but I think “protocol” gives a better connotation in that opening paragraph. You may notice that I more correctly use the “content format” description later on. Whatever, go ahead and crucify me for that if you’re feeling particularly pedantic today. I’ll still love you. You—yes, you, beloved reader. &amp;#8617;</summary></entry><entry><title type="html">Using ASCII waveforms to test real-time audio code</title><link href="https://goq2q.net/blog/tech/using-ascii-waveforms-to-test-real-time-audio-code" rel="alternate" type="text/html" title="Using ASCII waveforms to test real-time audio code" /><published>2021-10-12T00:00:00-06:00</published><updated>2021-10-13T00:00:00-06:00</updated><id>https://goq2q.net/blog/tech/using-ascii-waveforms-to-test-real-time-audio-code</id><content type="html" xml:base="https://goq2q.net/blog/tech/using-ascii-waveforms-to-test-real-time-audio-code">&lt;p&gt;I draw sound wave ASCII art in Q2Q’s source code. These ASCII art waveforms ensure that the real-time audio engine at the heart of Q2Q stays bug-free.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Software development best-practices dictate that if you want your software to be high-quality (who doesn’t?), you test your code, you &lt;a href=&quot;https://martinfowler.com/bliki/SelfTestingCode.html&quot;&gt;test it automatically&lt;/a&gt;, and you test it often (as part of a &lt;a href=&quot;https://martinfowler.com/articles/continuousIntegration.html&quot;&gt;continuous integration&lt;/a&gt; build process). In other words, you should make accidentally publishing bugs as difficult as possible. Q2Q, of course, has test suites to prevent regressions, and a CI system that makes sure all tests pass (just like any other good software project).&lt;/p&gt;

&lt;p&gt;Q2Q is a &lt;a href=&quot;http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing&quot;&gt;real-time audo&lt;/a&gt; application. It does things like starting/stopping sounds, fading/panning sounds, and looping/devamping sounds, and these kinds of features are mission-critical. They cannot fail or have bugs. Here’s the catch: audio programming is extremely tricky to get right. When I was first writing Q2Q, I spent days trying to get anything coherent out of the speakers &lt;em&gt;even at all&lt;/em&gt;. It’s very easy to get some buffer index wrong, or do a time conversion incorrectly, or forget to handle more than just mono and stereo signals, or even to just be off by a small number of samples without noticing.&lt;/p&gt;

&lt;p&gt;This is hard to write automated tests for – how are you supposed to write a test that asserts, “a one-second fade-out should work”? My initial thought was to take a sliding average (approximating loudness), and assert that it constantly decreases, for example. But then how would you test looping functionality? Or mixing different sounds together? Or crossfading? Trying to come up with how to test those invariants is very hard.&lt;/p&gt;

&lt;p&gt;I stumbled across &lt;a href=&quot;https://blog.janestreet.com/using-ascii-waveforms-to-test-hardware-designs/&quot;&gt;a post from Jane Street’s tech blog&lt;/a&gt; that describes a technique for testing hardware oscillators (which generate waveforms), where they render the oscillator’s output to text, which can be very easilly diffed. Additionally, the F# compiler &lt;a href=&quot;https://github.com/dotnet/fsharp/tree/dbf9a625d3188184ecb787a536ddb85a4ea7a587/tests/fsharp/typecheck/sigs&quot;&gt;has some tests&lt;/a&gt; (which it calls “baseline tests”) that test the new compiler’s output against output from an earlier known-good version of itself. A combination of these two approaches sounded very good to me.&lt;/p&gt;

&lt;p&gt;Q2Q employs this ASCII-waveform baseline testing technique to great success. Every time I work on a new feature, I manually create some test cases for the new feature. For example, if I were writing the component that performs fading and panning, I would first create a test case to exercise a simple fade (perhaps a short fade-out), and output to a simple array, instead of an actual output device (this is pretty easy as I use &lt;a href=&quot;https://github.com/naudio/NAudio&quot;&gt;NAudio&lt;/a&gt; for audio processing). Then, I would attempt to implement the feature. Then, I would use my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ASCIIWaveformRenderer&lt;/code&gt; to turn the output into an array of strings, acting as a visual representation of the data that would have been outputted to the audio device. I would run this in &lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/fsharp/tools/fsharp-interactive/&quot;&gt;F# interactive&lt;/a&gt;, so that if it looks good, I can copy-paste the result right back into the test code as the baseline to compare against from now on. If it didn’t look right, I would tweak the code until it does. Rinse and repeat for all the corner cases.&lt;/p&gt;

&lt;figure&gt;
  
&lt;a href=&quot;/assets/images/blog/2021-10-06-using-ascii-waveforms-to-test-real-time-audio-code/simple-fade-in-baseline.png&quot;&gt;&lt;img src=&quot;/assets/images/blog/2021-10-06-using-ascii-waveforms-to-test-real-time-audio-code/simple-fade-in-baseline.png&quot; alt=&quot;Foo&quot; /&gt;&lt;/a&gt;

  &lt;figcaption&gt;
Fade-in baseline test using an ASCII waveform.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  
&lt;a href=&quot;/assets/images/blog/2021-10-06-using-ascii-waveforms-to-test-real-time-audio-code/simple-looping-baseline.png&quot;&gt;&lt;img src=&quot;/assets/images/blog/2021-10-06-using-ascii-waveforms-to-test-real-time-audio-code/simple-looping-baseline.png&quot; alt=&quot;Foo&quot; /&gt;&lt;/a&gt;

  &lt;figcaption&gt;
A baseline test for a looping using slices. Notice how the slicer first plays straight through a signal, then loops the last part of the waveform.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This provides a great regression testing experience. Recently, while implementing &lt;a href=&quot;https://en.wikipedia.org/wiki/Pan_law&quot;&gt;pan laws&lt;/a&gt;, I noticed that the CI had started failing. I opened up the error log and was greeted with this:&lt;/p&gt;

&lt;figure&gt;
  
&lt;a href=&quot;/assets/images/blog/2021-10-06-using-ascii-waveforms-to-test-real-time-audio-code/fade-provider-baseline-failure.png&quot;&gt;&lt;img src=&quot;/assets/images/blog/2021-10-06-using-ascii-waveforms-to-test-real-time-audio-code/fade-provider-baseline-failure.png&quot; alt=&quot;Foo&quot; /&gt;&lt;/a&gt;

  &lt;figcaption&gt;
ASCII waveform baseline test failure.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is telling us that a test is failing because the system’s output did not match the expected ASCII waveform baseline.&lt;/p&gt;

&lt;p&gt;The tests for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FadeSampleProvider&lt;/code&gt; (the component that handles fading and panning), were catching a legitimate mistake. As you can see, storing the baseline as an ASCII waveform makes this much easier to debug than if it were to be an opaque array of raw sample data. &lt;a href=&quot;https://github.com/haf/expecto&quot;&gt;Expecto&lt;/a&gt;, the test framework I use, even gives a good enough visual diff there. You can kind of tell what is going wrong just by the picture – it’s supposed to be a fade out, as indicated by the first (green) waveform (so gradually decreasing in overall volume), and it kind of does this at first, but then the signal starts fading back in! Why was this happening? After some digging, it turns out that I had accidentally removed the clamping logic in the interpolation functions, thinking they were do-nothing code. These interpolations are simply mathematical functions&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, so you can put in numbers &lt;em&gt;you&lt;/em&gt; would consider invalid, and they will happily start doing funny things – like causing a fade-out to start fading back in. Oops!&lt;/p&gt;

&lt;p&gt;The interesting thing is that if these tests weren’t around, this bug probably would have gone unidentified, causing subtle glitches, for quite a while. Since the audio is streamed in real time, it is not processed all at once; rather, it is processed in buffered chunks. When the audio device is ready for more sound to play, it gives Q2Q an empty buffer, which Q2Q then fills with samples from the processing chain. This happens many time per second (as determined by the size of the buffer). &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FadeSampleProvider&lt;/code&gt; only calls the interpolation function when a fade is actually in progress – but it only re-decides this on the next buffer. Therefore, when a fade ends before the end of the buffer (which it likely would), it would exhibit this problem for the rest of that audio buffer. Buffer sizes are small enough (as measure in seconds) that it likely would have sounded like a millisecond-long click or pop, which would have been extremely difficult to attribute to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FadeSampleProvider&lt;/code&gt; in particular. I would have probably chalked it up to slow file reading, or inefficient code causing the device to drop some frames.&lt;/p&gt;

&lt;p&gt;ASCII-waveform baseline tests are great, but what about the cases I don’t know to write tests for? Can we take this even further? Check back for a future blog post – &lt;a href=&quot;/blog&quot;&gt;Property-based fuzz testing&lt;/a&gt; to the rescue!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;EDIT: since people were interested, I’ve posted the waveform-to-ASCII renderer as a snippet free to use: &lt;a href=&quot;http://www.fssnip.net/85g&quot;&gt;http://www.fssnip.net/85g&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;!-- TODO: write something about pan laws then link to it --&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;em&gt;I use different kinds of interpolation functions to implement the different fade shapes you can use, such as linear fades, constant-power fades, and compromise fades. &lt;a href=&quot;https://www.wolframalpha.com/input/?i=plot+%28sin%280.5x*pi%29%29%2C+%28x%29%2C+%280.5%28x%2Bsin%280.5x*pi%29%29%29+from+x%3D0+to+1&quot;&gt;Here’s a sample graph&lt;/a&gt; of some of these functions plotted together, and &lt;a href=&quot;https://www.wolframalpha.com/input/?i=plot+%28sin%280.5x*pi%29%29%2C+%28x%29%2C+%280.5%28x%2Bsin%280.5x*pi%29%29%29&quot;&gt;here’s that same graph&lt;/a&gt; without restricting the x axis to a specific range. Observe that the output makes sense as a fade volume for x values from 0 to 1, but start to get weird outside of that range. Hence, we need to clamp the x value between 0 and 1 before we pass it into the interpolation formula.&lt;/em&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>John Wostenberg</name></author><category term="tech" /><summary type="html">I draw sound wave ASCII art in Q2Q’s source code. These ASCII art waveforms ensure that the real-time audio engine at the heart of Q2Q stays bug-free.</summary></entry></feed>